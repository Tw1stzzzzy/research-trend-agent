#!/usr/bin/env python3
"""
å®Œæ•´ç³»ç»Ÿæµ‹è¯•è„šæœ¬
æµ‹è¯•ç ”ç©¶ä»£ç†ç³»ç»Ÿçš„æ‰€æœ‰ç»„ä»¶åŠŸèƒ½
"""

import os
import json
import requests
from datetime import datetime

def test_config():
    """æµ‹è¯•é…ç½®æ–‡ä»¶"""
    print("ğŸ”§ Testing Configuration...")
    try:
        import yaml
        with open("configs/config.yaml", "r") as f:
            config = yaml.safe_load(f)
        
        print(f"  âœ… Config loaded successfully")
        print(f"  ğŸ“Š LLM Provider: {config.get('llm_provider', 'NOT SET')}")
        print(f"  ğŸ”‘ GitHub Token: {'âœ… SET' if config.get('github', {}).get('token', '').startswith('ghp_') else 'âŒ NOT SET'}")
        print(f"  ğŸ“¡ Slack Webhook: {'âœ… SET' if config.get('slack', {}).get('webhook_url', '').startswith('https://') else 'âŒ NOT SET'}")
        return True
    except Exception as e:
        print(f"  âŒ Config error: {e}")
        return False

def test_llm():
    """æµ‹è¯•LLMè¿æ¥"""
    print("\nğŸ¤– Testing LLM Connection...")
    try:
        from processors.llm_client import LLMClient
        client = LLMClient()
        
        test_messages = [
            {"role": "user", "content": "Please respond with exactly: TEST_SUCCESS"}
        ]
        
        response = client.generate_response(test_messages, max_tokens=20)
        if "TEST_SUCCESS" in response:
            print(f"  âœ… LLM working correctly")
            return True
        else:
            print(f"  âš ï¸ LLM response unexpected: {response}")
            return False
            
    except Exception as e:
        print(f"  âŒ LLM error: {e}")
        return False

def test_github():
    """æµ‹è¯•GitHub API"""
    print("\nğŸ™ Testing GitHub API...")
    try:
        from fetchers.github_fetcher import GitHubFetcher
        import yaml
        
        with open("configs/config.yaml", "r") as f:
            config = yaml.safe_load(f)
        
        token = config.get('github', {}).get('token', '')
        if not token or token == "your-github-token-here":
            print("  âš ï¸ GitHub token not configured")
            return False
            
        fetcher = GitHubFetcher(token)
        # æµ‹è¯•ä¸€ä¸ªçŸ¥åä»“åº“
        stats = fetcher.get_repo_stats("https://github.com/pytorch/pytorch")
        
        if stats and stats.get('stars', 0) > 1000:
            print(f"  âœ… GitHub API working - PyTorch has {stats['stars']} stars")
            return True
        else:
            print(f"  âŒ GitHub API failed or unexpected response: {stats}")
            return False
            
    except Exception as e:
        print(f"  âŒ GitHub API error: {e}")
        return False

def test_slack():
    """æµ‹è¯•Slackè¿æ¥"""
    print("\nğŸ“± Testing Slack Integration...")
    try:
        import yaml
        
        with open("configs/config.yaml", "r") as f:
            config = yaml.safe_load(f)
        
        webhook_url = config.get('slack', {}).get('webhook_url', '')
        if not webhook_url or not webhook_url.startswith('https://hooks.slack.com'):
            print("  âš ï¸ Slack webhook not configured")
            return False
        
        test_payload = {
            "text": f"ğŸ§ª Test message from Research Agent - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "username": "Research Agent Test",
            "icon_emoji": ":test_tube:"
        }
        
        response = requests.post(webhook_url, json=test_payload, timeout=10)
        if response.status_code == 200:
            print("  âœ… Slack webhook working - test message sent")
            return True
        else:
            print(f"  âŒ Slack webhook failed: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"  âŒ Slack error: {e}")
        return False

def test_fetchers():
    """æµ‹è¯•è®ºæ–‡è·å–å™¨"""
    print("\nğŸ“š Testing Paper Fetchers...")
    try:
        from fetchers.cvf_fetcher import CVFFetcher
        
        # æµ‹è¯•CVF fetcher
        fetcher = CVFFetcher("https://openaccess.thecvf.com/CVPR2023", "CVPR")
        papers = fetcher.fetch_papers(max_papers=5)  # åªè·å–5ç¯‡æµ‹è¯•
        
        if papers and len(papers) > 0:
            print(f"  âœ… CVF fetcher working - got {len(papers)} papers")
            print(f"    ğŸ“„ Sample: {papers[0]['title'][:50]}...")
            return True
        else:
            print("  âŒ CVF fetcher failed")
            return False
            
    except Exception as e:
        print(f"  âŒ Fetcher error: {e}")
        return False

def test_processing():
    """æµ‹è¯•è®ºæ–‡å¤„ç†æµç¨‹"""
    print("\nâš™ï¸ Testing Paper Processing...")
    try:
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        output_files = [
            "output/raw_papers.json",
            "output/filtered_papers.json", 
            "output/scored_papers.json",
            "output/report.md"
        ]
        
        missing_files = []
        for file_path in output_files:
            if not os.path.exists(file_path):
                missing_files.append(file_path)
        
        if missing_files:
            print(f"  âš ï¸ Missing output files: {missing_files}")
            print("  ğŸ”„ Run 'python main.py' to generate outputs")
            return False
        
        # æ£€æŸ¥æ–‡ä»¶å†…å®¹
        with open("output/scored_papers.json", "r") as f:
            scored_papers = json.load(f)
        
        if len(scored_papers) > 0:
            avg_score = sum(p['score'] for p in scored_papers) / len(scored_papers)
            print(f"  âœ… Processing pipeline working")
            print(f"    ğŸ“Š {len(scored_papers)} papers scored, avg: {avg_score:.2f}")
            return True
        else:
            print("  âŒ No scored papers found")
            return False
            
    except Exception as e:
        print(f"  âŒ Processing error: {e}")
        return False

def run_full_test():
    """è¿è¡Œå®Œæ•´ç³»ç»Ÿæµ‹è¯•"""
    print("ğŸš€ Starting Full System Test")
    print("=" * 50)
    
    results = {
        "Config": test_config(),
        "LLM": test_llm(),
        "GitHub": test_github(),
        "Slack": test_slack(),
        "Fetchers": test_fetchers(),
        "Processing": test_processing()
    }
    
    print("\nğŸ“‹ Test Results Summary:")
    print("=" * 50)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{test_name:12} {status}")
        if result:
            passed += 1
    
    print("-" * 50)
    print(f"Total: {passed}/{total} tests passed ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("\nğŸ‰ All tests passed! System is ready to use.")
    else:
        print(f"\nâš ï¸ {total-passed} tests failed. Please check configuration.")
    
    return passed == total

if __name__ == "__main__":
    run_full_test() 