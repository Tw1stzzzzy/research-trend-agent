# Research Agent - Academic Paper Research Assistant

## ğŸ“– Project Overview

Research Agent is an intelligent academic paper research assistant system designed to help researchers efficiently track and analyze the latest paper trends from top AI conferences. The system provides personalized academic research reports through automated paper scraping, intelligent filtering, recognition assessment, and trend analysis.

## âœ¨ Key Features

- **ğŸ” Multi-Source Paper Scraping**: Automatically scrape papers from top AI conferences (ICLR, NeurIPS, ICML, CVPR, ECCV, ACL)
- **ğŸ¯ Intelligent Filtering**: Keyword-based filtering with GPT-4o abstract summarization for quick paper identification
- **ğŸ“Š Recognition Assessment**: Evaluate paper impact using PapersWithCode and GitHub metrics
- **ğŸ“ˆ Trend Analysis**: Generate research trend reports with hot topic statistics and conference distribution
- **ğŸ¤– Slack Integration**: Interactive bot queries and automatic report pushing capabilities

## ğŸ—ï¸ System Architecture

```
research_agent/
â”œâ”€â”€ main.py              # Main program entry
â”œâ”€â”€ slack_app.py         # Slack bot service
â”œâ”€â”€ fetchers/            # Paper scraping modules
â”‚   â”œâ”€â”€ openreview_fetcher.py
â”‚   â”œâ”€â”€ cvf_fetcher.py
â”‚   â”œâ”€â”€ acl_fetcher.py
â”‚   â”œâ”€â”€ pwcode_fetcher.py
â”‚   â””â”€â”€ github_fetcher.py
â”œâ”€â”€ processors/          # Data processing modules
â”‚   â”œâ”€â”€ filter_and_summarize.py
â”‚   â”œâ”€â”€ scoring.py
â”‚   â”œâ”€â”€ trend_analyzer.py
â”‚   â”œâ”€â”€ llm_summary.py
â”‚   â””â”€â”€ report_generator.py
â””â”€â”€ configs/             # Configuration files
    â”œâ”€â”€ config.yaml
    â””â”€â”€ keywords.txt
```

## ğŸš€ Quick Start

### System Requirements
- Python 3.8+
- Dependencies: `openreview-py`, `requests`, `beautifulsoup4`, `pyyaml`, `openai`, `slack-bolt`, `flask`

### Installation Steps

1. **Clone the repository**
```bash
git clone <repository-url>
cd research_agent
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Configuration setup**

Edit `configs/config.yaml`:
```yaml
# API Configuration
openai:
  api_key: "your-openai-api-key"

paperswithcode:
  api_key: "your-pwc-api-key"

github:
  token: "your-github-token"

slack:
  webhook_url: "your-slack-webhook-url"

# Scraping Configuration
fetch:
  since_date: "2024-01-01"
```

Edit `configs/keywords.txt` and add keywords of interest:
```
transformer
attention
autoregressive
diffusion
...
```

### Usage

#### 1. Batch Processing Mode
```bash
python main.py
```
After completion, check the `output/` directory for:
- `raw_papers.json` - Raw paper data
- `filtered_papers.json` - Filtered papers
- `scored_papers.json` - Scored papers
- `report.md` - Final research report

#### 2. Slack Bot Mode
```bash
# Set environment variables
export SLACK_BOT_TOKEN="your-bot-token"
export SLACK_SIGNING_SECRET="your-signing-secret"

# Start Slack application
python slack_app.py
```

Then use in Slack:
```
@Bot search transformer 2024
```

## ğŸ“‹ Configuration Guide

### API Key Acquisition
- **OpenAI API**: Visit [OpenAI Platform](https://platform.openai.com/) to obtain
- **PapersWithCode API**: Apply at [PWC API](https://paperswithcode.com/api/v1/docs/)
- **GitHub Token**: Create in GitHub Settings > Developer settings
- **Slack App**: Create application at [Slack API](https://api.slack.com/apps)

### Keyword Configuration
Add one keyword per line in `configs/keywords.txt`. The system performs exact matching (supports regex boundaries).

## ğŸ”§ Extension Development

### Adding New Paper Sources
1. Create a new fetcher class in the `fetchers/` directory
2. Implement the `fetch_papers()` method
3. Integrate the new data source in `main.py`

### Custom Scoring Algorithm
Modify the `calculate_score()` function in `processors/scoring.py` to adjust scoring weights and logic.

### Custom Report Templates
Edit the report generation logic and Markdown templates in `processors/report_generator.py`.

---

**Note**: Please ensure compliance with API usage terms and rate limits of academic platforms before using this system. 